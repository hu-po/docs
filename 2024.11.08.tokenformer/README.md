![thumbnail](thumbnail.png)

# Tokenformer

### Links

**YouTube:** https://youtube.com/live/yOT9WIL_2Kg

**X:** https://twitter.com/i/broadcasts/1vOxwrNwoBWJB

**Twitch:**

**Substack:**

**ResearchHub:**

**TikTok:**

**Reddit:**

### References

TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters
https://arxiv.org/pdf/2410.23168

Randomized Autoregressive Visual Generation
https://arxiv.org/pdf/2411.00776

DIFFERENTIAL TRANSFORMER
https://arxiv.org/pdf/2410.05258

Value Vector in Attention
https://youtu.be/eMlx5fFNoYc?si=trMnc4Dlf1clirte&t=922

Majority of params are MLP
https://youtu.be/9-Jl0dxWQs8?si=r066OC6wfnIeYNOv&t=1001

Orthogonality grows exponentially with the dimmensionality of the space
https://youtu.be/9-Jl0dxWQs8?si=CVUDv1vw0cmkcTbs&t=1208

Karpathy Attention
https://youtu.be/kCc8FmEb1nY?t=3858

Language is indexing and retrieval in brains
https://youtu.be/JTU8Ha4Jyfc?t=7890

Method of Locci
https://cognitivebias.io/uploads/ybias/image-6495c516a0377.png

Memories as a Sequence of visual querries
https://source.colostate.edu/an-elephant-never-forgets/

https://onlinelibrary.wiley.com/doi/10.1002/evan.21924

anamorphic sculptures
https://leonacreo.com/wp-content/uploads/2022/02/matthieu-robert-ortis-sculptures-anamorphose-illusion-5.jpg
